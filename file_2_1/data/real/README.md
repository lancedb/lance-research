# Data Files

This folder contains sample parquet files from various datasets. These are intended to provide real world samples of various
types of data. These files are samples from publicly available datasets and their licenses are suitable for research purposes.
We provide the files here to allow for accurate reproduction of our results and no other purpose. If you are interested in doing
your own research or using these files for other purposes then we recommend obtaining the data directly from the data sources
that we list below.

Note: The files are not checked into the Github repository because they are too large. Instead the files have been shared to
the Open Science Framework. They can be accessed at the following link:

These files should be downloaded before running any of the full scan experiments. A description of the categories and where
the data was sourced from can be found below.

# websites_trimmed.parquet

This file is a subset of [Common Crawl](https://commoncrawl.org) data. This data is subject to the terms
outlined in the [Common Crawl Terms of Use](https://commoncrawl.org/terms-of-use). It represents website data
collected by crawlers and released to the public. It was converted to Parquet and shared in the hugging face
repository [amazingvince/common-crawl-diverse-sample](https://huggingface.co/datasets/amazingvince/common-crawl-diverse-sample)

# code_trimmed.parquet

This file is a subset of code scraped from GitHub as part of a public
[dataset release from GitHub](https://github.blog/news-insights/research/making-open-source-data-more-available/).
The data was converted to Parquet and shared in the hugging face repository
[codeparrot/github-code](https://huggingface.co/datasets/codeparrot/github-code). The code itself is covered
by a number of different open source licenses as detailed in the repository.

# reviews_trimmed.parquet

This file is a collection of fine food reviews from the Amazon website. It was collected and release as
a dataset in the public domain as part of the Standford Network Analysis Project. It is available as a
[Kaggle dataset](https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews). The original file was CSV
and was converted to parquet by us.

# names_trimmed.parquet

This file is a collection of baby names. The source is US census data. The original source for this data
is the [Popular Baby Names](https://www.ssa.gov/oact/babynames/limits.html) dataset. It was converted
to Paruqet and shared in the hugging face repository
[jbrazzy/baby_names](https://huggingface.co/datasets/jbrazzy/baby_names)

# prompts_trimmed.parquet

This file is a collection off prompts to LLMs. It is a subset of [UltraChat](https://github.com/thunlp/UltraChat)
dataset. It was collected from a trimmed version of the dataset that has been shared on hugging face as
[ultrachat_200k](https://huggingface.co/datasets/HuggingFaceH4/ultrachat_200k). The dataset is released under
the MIT license.

# images_trimmed.parquet

This file is a collection of images. It is a dataset from the Frontier Research Team at takara.ai. It was
collected from a version of the dataset that has been shared on hugging face as
[image_captions](https://huggingface.co/datasets/takara-ai/image_captions).

# embeddings_trimmed.parquet

This file is a collection of vector embeddings. Specifically CLIP ViT-L/14 embeddings which are stored as
fixed size lists of 768 elements at float32 precision. It is a subset of the
[Laion-5b](https://laion.ai/blog/laion-5b/) dataset. It was collected from the dataset's website. The dataset
is released under the Creative Common CC-BY 4.0 license.

# dates_trimmed.parquet

This file is a collection of dates stored in an int32 encoding (days since the epoch). It is a subset of random
data generated by duckdb's TPC-H data generator. The data was created by us and is released into the public domain
under the CC0 license. It is important to note that the dates are not in sorted order. This would likely make
a difference for some algorithms but this paper is not a detailed study of compression formats.
