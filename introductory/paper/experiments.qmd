---
execute:
  echo: false
---
# Experiments

## Random Row-based Access

A "take" operation is a common file operation that selects rows from a file by row number.  This operation is
common when using secondary indices, which are indices that do not require the data to be ordered in any
particular way, and are typically stored separate from the data itself.  An indexed search first consults the
index to find the row number (or some other address) of the rows that satisfy the search criteria.  These row
numbers are then used to retrieve the rows of interest from the file.  This experiment is similar to the 
"Integration with Vector Search Pipeline" experiment from [@zeng2023empirical].

If the row numbers are scattered throughout the file then the take operation tests the file format's ability
to support small random access into the file.  This is something that columnar formats have traditionally
struggled with since an emphasis on encodings and compression increases the amount of data that must be fetched
to read a single cell.  As discussed earlier, Lance has been designed to prioritize this operation by ensuring
that random access to rows remains possible without requiring complex decoding or read amplification.

We evaluate Lance's performance on this type of operation by selecting K rows at random from a single file
containing the first million rows of the LAION-5B[@laion2022] English dataset.  We retrieve a single column of data.  This
column is either the similarity column (an 8-byte double value) or the image embedding (a fixed size list where
each value is a vector with 768 2-byte fp16 values).  All latency numbers are assuming the the file metadata is
cached in memory.  Cold start cases (where the metadata is not cached) add a small amount of latency to both
formats that does not depend on the other parameters.

One challenge we encountered is that Parquet libraries do not have builtin support for this type of operation.
We created a custom take routine for both parquet-rs and parquet-cpp[^1].  To emulate Lance we created a thread
task per row group.  Parquet files were written without compression and with 100,000 rows per row group as we
found these settings to perform best.  Latency measurements are averaged across many runs.  I/O measurements
are representative samples, since the actual I/O required varies slightly based on row id selection.

[^1]: The source code is available at https://github.com/lancedb/lance-research/tree/main/introductory/experiments/random-take

```{python}
#| label: fig-random-take-latency
#| echo: false
import matplotlib.pyplot as plt
import pyarrow.csv as csv

data = csv.read_csv("../experiments/random-take/local.csv").to_pandas()

fig, ax = plt.subplots()
plt.suptitle("Random Take Latency")
plt.xlabel("Take Size (# rows)")
plt.ylabel("Latency (ms)")

ax.set_yscale("log")

is_lance_data = (data["format"] == "lance") & (data["use_cache"] == True)

lance_double = data[is_lance_data & (data["column"] == "double")]
x = lance_double["take_size"]
y = lance_double["latency"]
plt.plot(x, y, marker="o", color="C0", ls="-", label="lance (double)")

lance_vector = data[is_lance_data & (data["column"] == "vector")]
x = lance_vector["take_size"]
y = lance_vector["latency"]
plt.plot(x, y, marker="o", color="C0", ls=":", label="lance (vector)")

is_parquet_data = (data["format"] == "parquet") & (data["use_cache"] == True)

parquet_double = data[is_parquet_data & (data["column"] == "double")]
x = parquet_double["take_size"]
y = parquet_double["latency"]
plt.plot(x, y, marker="o", color="C1", ls="-", label="parquet (double)")

parquet_vector = data[is_parquet_data & (data["column"] == "vector")]
x = parquet_vector["take_size"]
y = parquet_vector["latency"]
plt.plot(x, y, marker="o", color="C1", ls=":", label="parquet (vector)")

ax.set_xticks(lance_double["take_size"])

plt.legend()
plt.show()
```

The results are in @fig-random-take-latency.  The Lance format has significatly lower latency than Parquet in most situations.
When reading the 8-byte double column there are only a few Parquet data pages and Parquet quickly ends up reading
the entire column.  When reading large columns there are many data pages the data page overread hurts Parquet
significantly.  When taking a large number of rows from a small column Lance issues many small reads which hurts
performance.  This suggests that coalescing I/O requests may be a useful addition to Lance.  Parquet, since it
reads entire pages at a time, is effectively coalesced already.

```{python}
#| label: fig-random-take-io
#| echo: false
import matplotlib.pyplot as plt
import pyarrow.csv as csv

data = csv.read_csv("../experiments/random-take/local.csv").to_pandas()

fig, ax = plt.subplots()
plt.suptitle("Random Take I/O")
plt.xlabel("Take Size (# rows)")
plt.ylabel("Bytes Read (KiB)")

ax.set_yscale("log")

is_lance_data = (data["format"] == "lance") & (data["use_cache"] == True)

lance_double = data[is_lance_data & (data["column"] == "double")]
x = lance_double["take_size"]
y = lance_double["io_size"] / 1024.0
plt.plot(x, y, marker='o', color="C0", ls="-", label = "lance (double)")

lance_vector = data[is_lance_data & (data["column"] == "vector")] 
x = lance_vector["take_size"]
y = lance_vector["io_size"] / 1024.0
plt.plot(x, y, marker='o', color="C0", ls=":", label = "lance (vector)")

is_parquet_data = (data["format"] == "parquet") & (data["use_cache"] == True)

parquet_double = data[is_parquet_data & (data["column"] == "double")]
x = parquet_double["take_size"]
y = parquet_double["io_size"] / 1024.0
plt.plot(x, y, marker='o', color="C1", ls="-", label = "parquet (double)")

parquet_vector = data[is_parquet_data & (data["column"] == "vector")]
x = parquet_vector["take_size"]
y = parquet_vector["io_size"] / 1024.0
plt.plot(x, y, marker='o', color="C1", ls=":", label = "parquet (vector)")

ax.set_xticks(lance_double["take_size"])

plt.legend()
plt.show()
```

```{python}
#| label: fig-random-take-iops
#| echo: false
import matplotlib.pyplot as plt
import pyarrow.csv as csv

data = csv.read_csv("../experiments/random-take/local.csv").to_pandas()

fig, ax = plt.subplots()
plt.suptitle("Random Take IOPS")
plt.xlabel("Take Size (# rows)")
plt.ylabel("I/O Operations")

ax.set_yscale("log")

is_lance_data = (data["format"] == "lance") & (data["use_cache"] == True)

lance_double = data[is_lance_data & (data["column"] == "double")]
x = lance_double["take_size"]
y = lance_double["iops"]
plt.plot(x, y, marker='o', color="C0", ls="-", label = "lance (double)")

lance_vector = data[is_lance_data & (data["column"] == "vector")] 
x = lance_vector["take_size"]
y = lance_vector["iops"]
plt.plot(x, y, marker='o', color="C0", ls=":", label = "lance (vector)")

is_parquet_data = (data["format"] == "parquet") & (data["use_cache"] == True)

parquet_double = data[is_parquet_data & (data["column"] == "double")]
x = parquet_double["take_size"]
y = parquet_double["iops"]
plt.plot(x, y, marker='o', color="C1", ls="-", label = "parquet (double)")

parquet_vector = data[is_parquet_data & (data["column"] == "vector")]
x = parquet_vector["take_size"]
y = parquet_vector["iops"]
plt.plot(x, y, marker='o', color="C1", ls=":", label = "parquet (vector)")

ax.set_xticks(lance_double["take_size"])

plt.legend()
```

Figures @fig-random-take-io and @fig-random-take-iops show the I/O characteristics of the random take operation.
In both Lance and Parquet the latency was highly correlated with the amount of bytes read, suggesting the
operation is I/O bound in both formats.  The large number of IOPS required by Lance reinforces the need for coalescing.

```{python}
#| label: fig-random-take-filesystem
#| echo: false
import pandas as pd
import matplotlib.pyplot as plt
import pyarrow.csv as csv

data = csv.read_csv("../experiments/random-take/local.csv").to_pandas()
s3_data = csv.read_csv("../experiments/random-take/s3.csv").to_pandas()
s3_data["filesystem"] = "s3"
nfs_data = csv.read_csv("../experiments/random-take/nfs.csv").to_pandas()
nfs_data["filesystem"] = "nfs"
local_data = data[(data["take_size"] == 64) & (data["use_cache"] == True)].copy()
local_data["filesystem"] = "local"

combined_data = pd.concat([s3_data, nfs_data, local_data])

fig, ax = plt.subplots()
plt.suptitle("Random Take (64 rows) Vs. Filesystem")
plt.xlabel("FileSystem")
plt.ylabel("Latency (ms)")

ax.set_yscale("log")

is_lance_data = (combined_data["format"] == "lance")

lance_double = combined_data[is_lance_data & (combined_data["column"] == "double")]
x = lance_double["filesystem"]
y = lance_double["latency"]
plt.plot(x, y, marker='o', color="C0", ls="-", label = "lance (double)")

lance_vector = combined_data[is_lance_data & (combined_data["column"] == "vector")] 
x = lance_vector["filesystem"]
y = lance_vector["latency"]
plt.plot(x, y, marker='o', color="C0", ls=":", label = "lance (vector)")

is_parquet_data = (combined_data["format"] == "parquet")

parquet_double = combined_data[is_parquet_data & (combined_data["column"] == "double")]
x = parquet_double["filesystem"]
y = parquet_double["latency"]
plt.plot(x, y, marker='o', color="C1", ls="-", label = "parquet (double)")

parquet_vector = combined_data[is_parquet_data & (combined_data["column"] == "vector")]
x = parquet_vector["filesystem"]
y = parquet_vector["latency"]
plt.plot(x, y, marker='o', color="C1", ls=":", label = "parquet (vector)")

plt.legend()
plt.show()
```

Performance was also measured against different filesystems.  The previous results were using a fast local (NVME)
disk.  The take performance was also measured on NFS and S3 which are two popular cloud storage technologies.  The
results of this experiment are in figure @fig-random-take-filesystem.  S3 has a particularly high per-operation
overhead and Lance's performance suffered significantly as a result.

## Scanning

Scanning data is used in both OLAP queries and Data Loader workloads. As a comparison we'll be using Parquet, a common OLAP format, and TFRecord, a common data Loader format.

There are two major optimizations in Lance aimed at vector and unstructured data. The first is late materialization in queries with filters, which can save IO calls. The second are strong alignment of the on-disk format with the in-memory format.

### Overall scan performance

To provide an overall idea of performance while scanning, we compare Lance to Parquet [^parquet-scan-note] for two datasets. One is the first 1.8 million rows of the Laion-5B dataset, including a vector embedding column. The other is the `lineitem` table from the TPC-H dataset (with scale factor 10). The Laion dataset represents a typical computer vision dataset, while the TPC-H lineitem table represents a typical OLAP dataset.

[^parquet-scan-note]: The Parquet implementation we used to scan is PyArrow `15.0.0dev338`. The `lineitem` files were written with DuckDB 0.9.0, using default settings (SNAPPY compression). The Laion dataset was written with PyArrow. The vector column in this dataset was float16 type with 768 dimensions.

The first relevant factor in the scan performance is on-disk size, since this determines how much IO must be performed to scan the full table. The sizes are shown in @fig-dataset-size. In both cases, Lance is larger than Parquet. This is because Lance does not currently implement any encodings or compression which might reduce the on-disk size. This size difference is especially pronounced for the TCP-H dataset, which largely has data types that are highly compressible. The Laion dataset does not benefit nearly as much from compression because much of the dataset size comes from the vector embedding column, which has been found in @zeng2023empirical to be difficult to compress. In fact, if you write just the vector column out to files in Lance and Parquet, they will be roughly the same size.

```{r, warning=FALSE, message=FALSE}
library(gt)
library(ggplot2)
library(tidyr)
library(dplyr)

ggplot2::theme_set(ggplot2::theme_minimal())

# data <- read.csv("introductory/experiments/overall_scans/results.csv")
data <- read.csv("../experiments/overall_scans/results.csv")

data$format <- tools::toTitleCase(data$format)
data$dataset <- ifelse(data$dataset == "laion", "Laion", "TPC-H lineitem")
```


```{r}
#| label: fig-dataset-size
#| fig-cap: Size of datasets used in scan benchmarks
data |>
    filter(row_group_size == 102400) |>
    select(dataset, format, dataset_size_bytes) |>
    mutate(dataset_size_bytes = dataset_size_bytes / 1024 / 1024 / 1024) |>
    pivot_wider(names_from = format, values_from = dataset_size_bytes) |>
    mutate(Ratio = Lance / Parquet) |>
    gt(rowname_col = "dataset") |>
    tab_spanner(
        label="On-disk size (GB)",
        columns=c("Lance", "Parquet")
    ) |>
    fmt_number(
        columns = c("Lance", "Parquet", "Ratio"),
        decimals = 1
    )
```

The relative performance of scans in Lance verus Parquet varies between the datasets. For the TPC-H dataset, Lance is roughly 45% slower than Parquet. This is likely simply due to the relative on-disk size. Meanwhile in the Laion dataset, scanning Lance is 5x faster than scanning Parquet, likely due to it's more efficient decoding of the vector column.

It's worth noting that Lance's default setting is for row group size of 1024. This setting reduces scan performance of analytic data significantly, in both Lance and Parquet. This default setting is used since many Lance datasets have some wide columns such as images, where buffering more than 1024 rows before flushing to disk would mean excessive memory overhead. However, given this performance hit for scalar columns, future work may be necesary to decouple the page size of wide and small columns to allow for better OLAP scan performance while still maintaining reasonable memory requirements when writing data.

```{r}
#| label: fig-full-scan-runtime
#| fig-cap: Time to scan full datasets.
#| fig-height: 4
#| fig-width: 5
ggplot(data, aes(x = format, y = scan_time)) +
    geom_col() +
    facet_grid(dataset ~ row_group_size, labeller = "label_both") +
    labs(
      x="Format",
      y="Runtime (s)",
     )
```


### Late materialization

Late materialization can reduce IO costs by deferring the decision whether to load certain cells depending on the result of a filter. This is especially important when the projected columns are large, since the potential IO cost savings are substantial.

Late materialization is an engine optimization, and can be applied to any columnar format. However, the performance benefit of this optimization depends on the page structure of the format. If pages are large and cannot be sliced, then late materialization only will be beneficial to the extent that whole pages can be skipped. Put another way, any IO savings brought by late materialization can be outweighted by the read amplification from the serialization format. In Lance, vector and binary columns are laid out in a flat layout, which can be sliced at the cell-level. Therefore, Lance can read these large columns with zero read amplication, if we choose to. In practice, there is often a minimum IO size used that means that some small amount of read amplification is actually beneficial to reduce the total number of IO calls.

To demonstrate the performance benefit, we measured the performance of early versus late materialization strategies in Lance and Parquet. We compare against both PyArrow and DataFusion's Parquet scanners. PyArrow is commonly used in Parquet benchmarks in the literature but, unlike DataFusion, lacks a late materialization implementation. Therefore, we only provide results for late materialization in DataFusion. DataFusion currently does not support scanning vector columns (`FixedSizeList` in Arrow parlance), so it's results for vector embeddings are omitted as well.

As a test dataset, we used a sythetic dataset with three columns of varing cell sizes:

* `id`, an incrementing int64 column (8 bytes wide)
* `int`, a random int64 column (8 bytes wide)
* `vec`, a 768-dimensional 32-bit vector (~3KB wide)
* `img`, a random 40KB binary blob (40KB wide)

Vector embeddings (which `vec` represents) and compressed images (which `img` represents) are examples where compression doesn't help much but the cost of read amplification is high. There might be other types of columns, such as text documents, where there is a large size and cross-cell compression might be useful. But within-cell compression is likely to be a good tradeoff when considered with the requirement of low read-amplication.

The tables are written with 102,400 rows, with ten row groups of 10,240 rows. To isolate the effect of late materialization separate from statistics-based pruning, we write Parquet files without statistics. In Lance, we can disable the use of statistics when performing the scan.

```{r}
library(ggplot2)
library(dplyr)
library(gt)
library(tidyr)

# data_dir <- "introductory/experiments/late_materialization/"
data_dir <- "../experiments/late_materialization/"

runtime_results <- read.csv(paste0(data_dir, "runtime_results.csv"))
runtime_results$materialization_type <- as.factor(ifelse(runtime_results$late_materialization, "Late", "Early"))
runtime_results$columns <- factor(factor(runtime_results$columns), levels=c("int", "vec", "img"))

io_results <- read.csv(paste0(data_dir, "io_results.csv"))
io_results$materialization_type <- as.factor(ifelse(io_results$late_materialization, "Late", "Early"))
io_results$columns <- factor(factor(io_results$columns), levels=c("int", "vec", "img"))
```

In @fig-late-mat-runtime, we compare the time to scan the dataset with filters of varying selectivity for Parquet and Lance. For Lance, we show early and late materialization to show the impact of late materialization. 

At this row group size, Lance performance the scan faster than the two Parquet implementations, even for the small `int` column. In the early materialization case, Lance is reading roughly the same or more bytes from disk as the Parquet scans, as shown in @fig-late-mat-total-bytes. Despite this, Lance is able to read the image column with 4.5x less latency than Parquet (@fig-late-mat-table). One possible explanation for this difference is Lance's encodings require less decoding than Parquet to read into Arrow format. In fact, beyond some concatenation of buffers, Lance requires no transformation of binary column.

In cases where the projection contains a large column and is relatively selection, Lance is even faster. For the `img` column with 12.1% selectivity, Lance scanned 21 times faster than DataFusion. A significant portion of this difference comes from the amount of data read from disk: during the scan, Lance reads 70% less data than DataFusion does. This difference is enabled by Lance's ability to pushdown slicing at the IO level, reading only the relevant parts of the pages from disk. Meanwhile DataFusion can only slice Parquet at the row group boundaries. (It's possible a future implementation of Parquet could slice at the page boundaries.) This pattern is clearly shown in @fig-late-mat-total-bytes, where the bytes read from disk by Lance smoothly scales with the number of rows selected by the filter, while DataFusion's jump each time a row group boundary is crossed.

Because the filter being used selects a contiguous range of rows, DataFusion will only ever have one partial read of a group, limiting the read amplification to no more than 400MB in the case of the `img` column. However, if the filter results is more broken up, the read amplification will be stronger.

```{r}
#| label: fig-late-mat-runtime
#| fig-cap: Scan time for early versus late materialization.
#| fig-height: 3.5
#| fig-width: 5
ggplot(runtime_results, aes(color=library, linetype=materialization_type, x=selectivity, y=runtime)) +
 geom_line() +
 facet_wrap(~ columns, scales = "free_y", labeller = "label_both") +
 scale_x_continuous(label=scales::label_percent()) +
 theme(legend.position = "bottom") +
 labs(
  linetype="Materialization type",
  x="Filter selectivity",
  y="Runtime (s)",
  color="Format",
 )
```



```{r}
#| label: fig-late-mat-table
#| fig-cap: Read performance for `img` column.
chosen_selectivity <- sort(unique(runtime_results$selectivity))[1]

low_selectivity_results <- runtime_results |>
    filter(selectivity == chosen_selectivity & columns == "img") |>
    left_join(io_results, by=c("library", "columns", "materialization_type", "selectivity")) |>
    select(library, materialization_type, runtime, total_bytes)

lance_baseline <- low_selectivity_results |> filter(library == "Lance") |>
    rename(runtime_lance = runtime, total_bytes_lance = total_bytes) |>
    select(materialization_type, runtime_lance, total_bytes_lance)

low_selectivity_results |>
    left_join(lance_baseline, by=c("materialization_type"))  |>
    mutate(
        runtime_ratio = runtime / runtime_lance,
        total_bytes_ratio = total_bytes / total_bytes_lance,
        total_bytes = total_bytes / 1024 / 1024,
        materialization_type = paste(materialization_type, "Materialization")
    ) |>
    select(materialization_type, library, runtime, runtime_ratio, total_bytes, total_bytes_ratio) |>
    group_by(materialization_type) |>
    gt(rowname_col="library") |>
    fmt_number(runtime) |>
    fmt_number(columns = c("runtime_ratio", "total_bytes_ratio"), decimals=1, pattern="{x}x") |>
    fmt_number(total_bytes, decimals=0) |>
    cols_label(
        ends_with("ratio") ~ "",
        runtime = "Latency (s)",
        total_bytes = "Bytes Read (MB)",
    ) #|>
    # tab_header(
    #     title = sprintf("Read performance for img column at %.01f%% selectivity", chosen_selectivity * 100)
    # )
```


In @fig-late-mat-total-bytes, we compare the total bytes read during the scans performed above. Both DataFusion and Lance are able to skip a substantial amount of IO, but Lance is able to smoothly scale while DataFusion jumps up each time it reaches a new row group boundary.

<!-- TODO: add a case where the filter is more random -->

```{r}
#| label: fig-late-mat-total-bytes
#| fig-cap: Bytes read for early versus late materialization.
#| fig-height: 3.5
#| fig-width: 5
ggplot(io_results, aes(color=library, linetype=materialization_type, x=selectivity, y=total_bytes)) +
 geom_line() +
 facet_wrap(~ columns, scales = "free_y", labeller = "label_both") +
 scale_y_continuous(label=scales::label_bytes(unit="MB")) +
 scale_x_continuous(label=scales::label_percent()) +
 theme(legend.position = "bottom") +
 labs(
  linetype="Materialization type",
  x="Filter selectivity",
  y="Total bytes read",
  color="Library",
 )
```


In @fig-late-mat-num-ios, we compare the total number of IO calls performed during the scans performed above.

```{r}
#| label: fig-late-mat-num-ios
#| fig-cap: The total number of IO calls made while scanning a single column with filter.
#| fig-height: 4
ggplot(io_results, aes(color=library, linetype=materialization_type, x=selectivity, y=num_ios)) +
 geom_line() +
 facet_wrap(~ columns, scales = "free_y") +
 scale_x_continuous(label=scales::label_percent()) +
 theme(legend.position = "bottom")
```


This reduction of IO is important for three factors: (1) query latency, (2) cost, and (3) scalability. The reduction in query latency is shown directly in @fig-late-mat-runtime. The reduction in IOs has direct cost benefits in object storage systems like S3 that charge per request. A 40% reduction in requests translates directly into reduction in costs. Finally, reduced IO calls also means the throughput limits of the storage system aren't hit as soon, improving the ability to scale the system.
