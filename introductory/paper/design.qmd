# Design

Lance was created as a data storage solution designed to handle emerging AI workloads
such as autonomous driving cars, LLMs, recommendation systems, and RAG.
These workloads have unique characteristic that cause existing storage solutions, many
of them based on popular columnar formats like parquet and orc, to perform poorly.
This section describes common patterns in these systems that are not handled well by
existing formats.  These patterns motivated the design of the Lance format.

A significant aspect of AI workloads is that these workloads often have large columns.
For example, LLMs and recommendation systems make extensive use of vector embeddings.
ViT-L, a common vector embedding, contains 768 floating point values per row [citation needed].
Graphical workloads often contain images are stored along the metadata and these
images are large variable length binary columns that are already compressed.  Workloads
that process sensor data can often contain large structures such as lidar data or signal
waveforms.

AI workloads have seen secondary indices become essential for searching vector columns.
Secondary vector indices such as IVF_PQ and HNSW are common approaches for handling
top-n queries against image or text embeddings.  Secondary index queries output a
sequence of logical row offsets which match the search criteria.  These row offsets
are non-sequential and scattered randomly throughout a file which can make it difficult
to retrieve the matching rows.

The previous criteria are difficult for current columnar storage systems and might suggest
a row based approach.  However, AI workloads are similarly ill-suited for row based
formats.  AI datasets, like other ML datasets, typically store a large number of
features and rely on efficient column projection.  Furthermore, AI training tools such as
pytorch or tensorflow expect vectors to be delivered in large contiguous batches. A row based
format would require an expensive transpose operation to feed these tools effectively.

## Table Layout

Lance is both a file format and a table format.  As a table format Lance describes how
a data table should be distributed across data files, deletion files, manifest files,
transaction files, and index files.  The table format also describes procedures for how
these files are updated as changes are made to the table such as appending new data,
modifying existing data, or updating an index.

The Lance table format is inspired by other modern table formats such as Delta Lake and
Iceberg.  Files, once written, are immutable.  This makes it possible to use popular
cloud based object storage solutions which do not support modifying existing files.
Coordination mechanisms are described which can be used to achieve ACID data transactions.

## Apache Arrow Compatibility

Lance makes extensive use of the Apache Arrow columnar layout for its data.  Lance uses
Arrow's type system for both its file format and its table format.  Lance libraries use
Arrow as the in-memory representation.  This enables seamless integration with tools like
Apache Datafusion[@datafusion] or DuckDb[@duckdb].  In addition, Lance's encodings are
designed to be as similar to the Arrow layout as possible so as to minimize decoding cost.

## File Layout

The Lance file format is a part of the table format.  However, a Lance file is also fully
self describing and can stand on its own if needed.  Lance files serialize Arrow data into
a format suitable for storage.  Like other columnar systems such as Artus (see @procella2019)
and BtrBlocks (see @btrblocks), Lance avoids generic compression in favor of simple encodings.
Furthermore, while those systems allow reading a single row without *decoding* a full page,
Lance includes encodings that can read only the relevant portions of a page to retrieve a
single value.  Lance files are also designed to support small row groups with as little
overhead as possible.

### Overall Structure

A Lance file starts with a sequence of row groups.  Each row group consists of a sequence
of columns.  After the last row group there is a metadata block.  This metadata includes
column metadata (such as page locations) and statistics (i.e. zone maps).  After this there
is an optional manifest block which contains the schema of the data.  Finally, there is a
footer, which contains the file version, the position of the metadata block, and a magic number.

### Row Groups

Data files are partitioned into row groups.  The reason for doing this is to limit the amount
of memory needed to write a data file.  Writers typically receive data as rows or batches of
rows.  Since each column is written contiguously within a row group we need to be able to
buffer an entire row group in memory before writing it to disk.  Since rows within an AI
workload are so large, row group sizes in Lance tend to be much smaller than other formats.

For example, the LAION-5B dataset is a popular dataset used to train image generation models.
The first 1024 rows of this dataset, in the Arrow in-memory layout, occupy 3,556 KiB of RAM.
This is roughly equivalent to 25,000 rows of TPC-H data.  Row group sizes of 1024 are not
uncommon when working with Lance data.

The disadvantage of smaller row groups is that columns are broken into smaller chunks of
contiguous data.  This means that column reads must be broken into a large number of
small reads.  These reads cannot be easily coalesced, especially if the schema is wide,
when only a few columns are read from disk.  This has a significant impact on IOPS-bound
storage systems such as S3.

### Column Encodings

Column data is written into a row group, in DFS order.  Lance limits encodings to those
that support sub-linear random access and does not do any compression.  Compression and
bit packing encodings require storing multiple values in chunks or pages.  Reading one
value from a chunk requires reading the entire page.  When working with very large values
like those present in AI workloads this either leads to pages with only one or a few
values (which defeats the purpose) or leads to large pages that are expensive to read
from disk.  As a result, Lance currently only supports the following encodings.

#### Plain Encoding

Plain encoding, suitable for fixed sized values, simply writes the values in a
single contiguous buffer onto the disk.  This is identical to the Arrow layout for
fixed-width types.

#### Variable-Length Encoding

Variable-length encoding writes a buffer of offsets and a buffer of the variable
length data.  Looking up a value requires two reads, one to get the position of the
data and the second to read the data itself.  This is similar to the Arrow layout for
variable-length types except file offsets are written instead of lengths.

#### Dictionary Encoding

Dictionary encoding is used for Arrow dictionary types.  The dictionary and the
indices are written separately.  The indices are written with plain encoding.

### Page Table

After all of the row groups are written the Lance file then contains the metadata.
The first part of the metadat is the page table.  This table contains the file offset
and byte length of each column in each row group.  This structure must be read before
any random access can occur.  It is expected that this table will be cached (in memory
or fast ephemeral storage) in most use cases.

### Statistics

The second part of the metadata consists of row group statistics.  This optional structure
currently stores the minimum, maximum, and null count of each column in each row group.
This can be used for pushdown filtering.  The statistics are most effective when the data
is ordered by the filter column which then serves as a clustered or primary index.  However,
sinces row groups tend to be small, some opportunistic filtering can happen for other data
patterns as well.

### Manifest

The final part of the metadata is the manifest.  This structure is optional.  It is a protobuf
encoded structure that contains the schema of the data file.  Since Lance is a table format
the schema will usually already be known and is not typically read when reading Lance files.

### Metdata Footer

Following the metadata is a protobuf-encoded footer which contains the file offset of the
page table, statistics, and manifest.

### File Footer

The final 16 bytes of a Lance file contain the file version, the position of the metadata
footer, and a magic number that can be used to identify a file as a Lance file.

## Discussion

The Lance file format is similar to other columnar formats such as parquet and orc.  The key
differences in Lance are the plain encodings, lack of compression, and minimal metadata.
These are essential for AI workloads because they allow for small row groups, which makes it
possible to write datasets with limited RAM, and they allow for fast random access with
minimal overread.

Another key difference is in the design and development of the Lance libraries themselves.
For example, it is possible for parquet to write small row groups, simple encodings, and
keep a page lookup.  However, we are not aware of any public parquet reader that can take
advantage of the fact that vectors are plain-encoded to perform sublinear random access.
The Arrow IPC format is also capable of sub-linear random access but it lacks a record batch
lookup in the file metadata.  These libraries have been designed without AI workloads in
mind.  Their default configuration is poorly suited for AI workloads and the libraries lack
random access features even when the format is capable of it.