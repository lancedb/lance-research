---
format: acm-pdf

# use keep-tex to cause quarto to generate a .tex file
# which you can eventually use with TAPS
keep-tex: true

bibliography: bibliography.bib

title: "Lance: A columnar format for AI data lakes"

author:
  - name: Will Jones
    affiliations:
      - name: LanceDB
        country: USA
    # orcid: 0000-0003-2402-304X
    email: willjones127@gmail.com
    # url: https://mm218.dev
  - name: Weston Pace
    affiliations:
      - name: LanceDB
        country: USA
  - name: Rob Meng
    affiliations:
      - name: LanceDB
        country: USA
  - name: Chang She
    affiliations:
      - name: LanceDB
        country: USA

  - name: Qian Zhu
    affiliations:
      - name: LanceDB
        country: USA
    # email:
  - name: Lei Xu
    affiliations:
      - name: LanceDB
        country: USA
    # email:

# acm-specific metadata
acm-metadata:
  # comment this out to make submission anonymous
  # anonymous: true

  # comment this out to build a draft version
  final: true

  # comment this out to specify detailed document options
  acmart-options: sigconf

  # acm preamble information
  copyright-year: 2024
  acm-year: 2024
  copyright: acmcopyright
  doi: XXXXXXX.XXXXXXX
  conference-acronym: "Conference acronym 'XX"
  conference-name: |
    Make sure to enter the correct
    conference title from your rights confirmation emai
  conference-date: June 03--05, 2018
  conference-location: Woodstock, NY
  price: "15.00"
  isbn: 978-1-4503-XXXX-X/18/06

  # if present, replaces the list of authors in the page header.
  shortauthors: Trovato et al.

  # The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
  # Please copy and paste the code instead of the example below.
  ccs: |
    \begin{CCSXML}
    <ccs2012>
     <concept>
      <concept_id>10010520.10010553.10010562</concept_id>
      <concept_desc>Computer systems organization~Embedded systems</concept_desc>
      <concept_significance>500</concept_significance>
     </concept>
     <concept>
      <concept_id>10010520.10010575.10010755</concept_id>
      <concept_desc>Computer systems organization~Redundancy</concept_desc>
      <concept_significance>300</concept_significance>
     </concept>
     <concept>
      <concept_id>10010520.10010553.10010554</concept_id>
      <concept_desc>Computer systems organization~Robotics</concept_desc>
      <concept_significance>100</concept_significance>
     </concept>
     <concept>
      <concept_id>10003033.10003083.10003095</concept_id>
      <concept_desc>Networks~Network reliability</concept_desc>
      <concept_significance>100</concept_significance>
     </concept>
    </ccs2012>
    \end{CCSXML}

    \ccsdesc[500]{Computer systems organization~Embedded systems}
    \ccsdesc[300]{Computer systems organization~Redundancy}
    \ccsdesc{Computer systems organization~Robotics}
    \ccsdesc[100]{Networks~Network reliability}

  keywords:
    - datasets
    - neural networks
    - gaze detection
    - text tagging

  # if uncommented, this produces a teaser figure
  #
  # teaser:
  #   image: sampleteaser
  #   caption: figure caption
  #   description: teaser description

include-in-header:
  - table_workaround.tex

abstract: |
  A clear and well-documented \LaTeX\ document is presented as an
  article formatted for publication by ACM in a conference proceedings
  or journal publication. Based on the "acmart" document class, this
  article presents and explains many of the common variations, as well
  as many of the formatting elements an author may use in the
  preparation of the documentation of their work.

---

{{< include intro.qmd >}}

# Related work

{{< include design.qmd >}}

{{< include experiments.qmd >}}

# Future work

In this paper, we demonstrated Lance's optimizations for vector and unstructed data. We compared this to existing data lake formats, such as Parquet.

Lance currently does not support null values in most data types. We will be implementing this, while attempting to maintain the sliceability of buffers to the extent possible.

To be useful in a broader set of use cases, Lance will need additional encoding schemes. While plain encodings works well for vector embeddings and compressed binary blobs, other data types will require encodings that provide compression, as seen in other state-of-the-art storage systems. Like Artus (@procella2019), Lance will prefer encodings that support single-value and range access, and avoid those that require decoding full pages. In additional, we may also implement novel encodings to handle other AI data types, such as sparse tensors.

# Conclusion


# References {-}

